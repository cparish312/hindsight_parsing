{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract tweet entities from annotations db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/Users/connorparish/code/hindsight\")\n",
    "sys.path.insert(0, \"../../../hindsight/hindsight_server/\")\n",
    "from annotation_helpers import add_hindsight_frame_path, get_entity_image, visualize_annotations, get_entity_image\n",
    "from annotations_db import HindsightAnnotationsDB\n",
    "\n",
    "from db import HindsightDB\n",
    "from utils import make_dir, ocr_results_to_str, add_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_db = HindsightAnnotationsDB()\n",
    "db = HindsightDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations = annotations_db.get_annotations()\n",
    "all_annotations['x2'] = all_annotations['x'] + all_annotations['w']\n",
    "all_annotations['y2'] = all_annotations['y'] + all_annotations['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tweet_annotations = all_annotations.loc[~all_annotations['parent_annotation_id'].isnull()]\n",
    "all_tweet_annotations = all_annotations.loc[all_annotations['model_version'] == model_version]\n",
    "all_tweet_annotations = all_tweet_annotations.loc[~all_tweet_annotations['label'].isnull()]\n",
    "frame_annotations = all_annotations .loc[~all_annotations['frame_id'].isnull()]\n",
    "annotated_frame_ids = {int(i) for i in frame_annotations['frame_id']}\n",
    "all_ocr_res = db.get_frames_with_ocr(frame_ids=annotated_frame_ids)\n",
    "all_ocr_res['x2'] = all_ocr_res['x'] + all_ocr_res['w']\n",
    "all_ocr_res['y2'] = all_ocr_res['y'] + all_ocr_res['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap_and_positions(row, annotation_row):\n",
    "    # Coordinates of the OCR rectangle\n",
    "    ocr_x1 = row['x']\n",
    "    ocr_y1 = row['y']\n",
    "    ocr_x2 = row['x2']\n",
    "    ocr_y2 = row['y2']\n",
    "    \n",
    "    # Coordinates of the overlapping area\n",
    "    overlap_x1 = max(ocr_x1, annotation_row['x'])\n",
    "    overlap_y1 = max(ocr_y1, annotation_row['y'])\n",
    "    overlap_x2 = min(ocr_x2, annotation_row['x2'])\n",
    "    overlap_y2 = min(ocr_y2, annotation_row['y2'])\n",
    "    \n",
    "    # Width and height of the OCR rectangle\n",
    "    ocr_width = ocr_x2 - ocr_x1\n",
    "    ocr_height = ocr_y2 - ocr_y1\n",
    "    \n",
    "    # Width and height of the overlapping area\n",
    "    overlap_width = max(0, overlap_x2 - overlap_x1)\n",
    "    overlap_height = max(0, overlap_y2 - overlap_y1)\n",
    "    \n",
    "    # Check for no overlap or invalid dimensions\n",
    "    if overlap_width <= 0 or overlap_height <= 0 or ocr_width <= 0 or ocr_height <= 0:\n",
    "        return None  # No overlap or invalid rectangle dimensions\n",
    "    \n",
    "    # Assuming left-to-right text direction\n",
    "    # Relative start and end positions along the x-axis\n",
    "    relative_start = (overlap_x1 - ocr_x1) / ocr_width\n",
    "    relative_end = (overlap_x2 - ocr_x1) / ocr_width\n",
    "    \n",
    "    # Ensure relative positions are within [0,1]\n",
    "    relative_start = max(0, min(1, relative_start))\n",
    "    relative_end = max(0, min(1, relative_end))\n",
    "    \n",
    "    return relative_start, relative_end\n",
    "\n",
    "def extract_text_within_overlap(row):\n",
    "    text = row['text']\n",
    "    relative_start, relative_end = row['relative_positions']\n",
    "    \n",
    "    # Total length of the text\n",
    "    text_length = len(text)\n",
    "    \n",
    "    # Calculate character indices corresponding to the overlap\n",
    "    start_char = int(text_length * relative_start)\n",
    "    end_char = int(text_length * relative_end)\n",
    "    \n",
    "    # Ensure indices are within the bounds of the text\n",
    "    start_char = max(0, min(text_length, start_char))\n",
    "    end_char = max(0, min(text_length, end_char))\n",
    "    \n",
    "    # Extract the text segment\n",
    "    extracted_text = text[start_char:end_char]\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "def get_sub_df(df, annotation_row):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Compute overlap positions\n",
    "    overlap_results = df.apply(\n",
    "        lambda row: compute_overlap_and_positions(row, annotation_row), axis=1)\n",
    "    \n",
    "    # Remove rows with no overlap\n",
    "    df = df[overlap_results.notnull()]\n",
    "    df['relative_positions'] = overlap_results.dropna()\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    # Extract the portion of text within the overlapping area\n",
    "    df['extracted_text'] = df.apply(lambda row: extract_text_within_overlap(row), axis=1)\n",
    "    \n",
    "    # Adjust coordinates relative to the annotation rectangle (optional)\n",
    "    df['x'] = df['x'] - annotation_row['x']\n",
    "    df['y'] = df['y'] - annotation_row['y']\n",
    "    df['x2'] = df['x2'] - annotation_row['x']\n",
    "    df['y2'] = df['y2'] - annotation_row['y']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_labels = {'ad_icon',\n",
    " 'community_notes',\n",
    " 'image_content_source',\n",
    " 'impresssions',\n",
    " 'likes',\n",
    " 'more_posted',\n",
    " 'quoted_tweet',\n",
    " 'replies',\n",
    " 'retweets',\n",
    " 'time_since_post',\n",
    " 'tweet_image_content',\n",
    " 'tweet_text',\n",
    " 'user_association_image',\n",
    " 'user_handle',\n",
    " 'user_image',\n",
    " 'username',\n",
    " 'verified_check'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_labels = {\n",
    " 'community_notes',\n",
    " 'image_content_source',\n",
    " 'impresssions',\n",
    " 'likes',\n",
    " 'replies',\n",
    " 'retweets',\n",
    " 'time_since_post',\n",
    " 'tweet_text',\n",
    " 'user_handle',\n",
    " 'username'}\n",
    "\n",
    "tweet_binary_labels = {\n",
    "    \"ad_icon\",\n",
    "    \"verified_check\",\n",
    "    \"user_association_image\",\n",
    "    \"user_image\",\n",
    "    \"tweet_image_content\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_tweet_labels(labels_df):\n",
    "    labels_df = labels_df.copy()\n",
    "    labels_df = labels_df.sort_values(by=[\"y\"], ascending=True)\n",
    "    return labels_df.drop_duplicates(subset=['label'], keep=\"first\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tweets = list()\n",
    "for parent_annotations_id in set(all_tweet_annotations['parent_annotation_id']):\n",
    "    # if len(parsed_tweets) > 50:\n",
    "    #     continue\n",
    "    parent_annotation_row = all_annotations.loc[all_annotations['id'] == parent_annotations_id].iloc[0]\n",
    "    frame_ocr_res = all_ocr_res.loc[all_ocr_res['frame_id'] == int(parent_annotation_row['frame_id'])]\n",
    "    tweet_ocr_res = get_sub_df(frame_ocr_res, parent_annotation_row)\n",
    "\n",
    "    tweet_d = {\"parent_annotations_id\" : int(parent_annotations_id)}\n",
    "    tweet_annotations = all_tweet_annotations.loc[all_tweet_annotations['parent_annotation_id'] == parent_annotations_id]\n",
    "    \n",
    "    all_tweet_annotation_labels = set(tweet_annotations['label'])\n",
    "    if \"quoted_tweet\" in all_tweet_annotations:\n",
    "        quoted_tweet_row = all_tweet_annotations.loc[all_tweet_annotations['label'] == \"quoted_tweet\"].iloc[0]\n",
    "        quoted_tweet_annotations = get_sub_df(tweet_annotations, quoted_tweet_row)\n",
    "        quoted_tweet_annotations_ids = set(quoted_tweet_annotations_ids['id'])\n",
    "        tweet_annotations = tweet_annotations.loc[~tweet_annotations['id'].isin(quoted_tweet_annotations_ids)] # Remove quoted tweet annotations from tweet_annotations\n",
    "        quoted_tweet_annotations = quoted_tweet_annotations.loc[quoted_tweet_annotations['label'] != \"quoted_tweet\"]\n",
    "        quoted_tweet_annotations_dedupe = dedupe_tweet_labels(quoted_tweet_annotations_dedupe)\n",
    "\n",
    "        quoted_tweet_ocr_res = get_sub_df(tweet_ocr_res, quoted_tweet_row)\n",
    "        \n",
    "        quoted_tweet_d = {}\n",
    "        for i, row in quoted_tweet_annotations_dedupe.iterrows():\n",
    "            if row['label'] in tweet_binary_labels:\n",
    "                quoted_tweet_d[row['label']] = True\n",
    "            else:\n",
    "                label_ocr_res = get_sub_df(quoted_tweet_ocr_res, row)\n",
    "                if len(label_ocr_res) > 0:\n",
    "                    quoted_tweet_d[row['label']] = \" \".join(label_ocr_res['extracted_text'])\n",
    "                else:\n",
    "                    quoted_tweet_d[row['label']] = -1\n",
    "        tweet_d[\"quoted_tweet\"] = quoted_tweet_d\n",
    "        tweet_annotations = tweet_annotations.loc[tweet_annotations['label'] != \"quoted_tweet\"] # In case multiple quoted_tweet labels\n",
    "\n",
    "    tweet_annotations = dedupe_tweet_labels(tweet_annotations)\n",
    "    for i, row in tweet_annotations.iterrows():\n",
    "        if row['label'] in tweet_binary_labels:\n",
    "            tweet_d[row['label']] = True\n",
    "        else:\n",
    "            label_ocr_res = get_sub_df(tweet_ocr_res, row)\n",
    "            if len(label_ocr_res) > 0:\n",
    "                tweet_d[row['label']] = \" \".join(label_ocr_res['extracted_text'])\n",
    "            else:\n",
    "                tweet_d[row['label']] = -1 # For when there is an obj detected but no ocr results\n",
    "    \n",
    "    parsed_tweets.append(tweet_d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id_to_timestamp = {f : t for f, t in zip(all_ocr_res['frame_id'], all_ocr_res['timestamp'])}\n",
    "parent_annotation_id_to_frame_id = {i : f for i, f in zip(all_annotations['id'], all_annotations['frame_id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tweets_df = pd.DataFrame(parsed_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tweets_df['frame_id'] = parsed_tweets_df['parent_annotations_id'].map(parent_annotation_id_to_frame_id)\n",
    "parsed_tweets_df['timestamp'] = parsed_tweets_df['frame_id'].map(frame_id_to_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tweets_df.to_csv(f\"all_tweets-{int(time.time())}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns = {\n",
    " 'impresssions',\n",
    " 'likes',\n",
    " 'replies',\n",
    " 'retweets',\n",
    " 'time_since_post',\n",
    " 'user_handle',\n",
    " 'user_image',\n",
    " 'username'}\n",
    "cleaned_parsed_tweets_df = parsed_tweets_df.dropna(subset=needed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_tweets = set(parsed_tweets_df['parent_annotations_id']) - set(cleaned_parsed_tweets_df['parent_annotations_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/2c9vmfhd35bgwc_6h0q80d180000gn/T/ipykernel_37605/853381407.py:1: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  cleaned_parsed_tweets_df['5min_interval'] = cleaned_parsed_tweets_df.groupby(pd.Grouper(key='datetime_local', freq='5T'))['datetime_local'].transform('min')\n",
      "/var/folders/c_/2c9vmfhd35bgwc_6h0q80d180000gn/T/ipykernel_37605/853381407.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_parsed_tweets_df['5min_interval'] = cleaned_parsed_tweets_df.groupby(pd.Grouper(key='datetime_local', freq='5T'))['datetime_local'].transform('min')\n"
     ]
    }
   ],
   "source": [
    "cleaned_parsed_tweets_df['5min_interval'] = cleaned_parsed_tweets_df.groupby(pd.Grouper(key='datetime_local', freq='5T'))['datetime_local'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_columns = {\n",
    " 'tweet_text',\n",
    " 'username',\n",
    " 'tweet_image_content',\n",
    " '5min_interval'}\n",
    "# Add time and drop if within 5 mins\n",
    "cleaned_parsed_tweets_df = cleaned_parsed_tweets_df.drop_duplicates(subset=dupe_columns, keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_parsed_tweets_df.to_csv(\"extracted_tweets_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_annotations_id = random.choice(list(dropped_tweets))\n",
    "parent_annotations_id = 120943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[414], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m parent_annotation_row \u001b[38;5;241m=\u001b[39m all_annotations\u001b[38;5;241m.\u001b[39mloc[all_annotations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m parent_annotations_id]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m frame_ocr_res \u001b[38;5;241m=\u001b[39m all_ocr_res\u001b[38;5;241m.\u001b[39mloc[all_ocr_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparent_annotation_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mframe_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m      3\u001b[0m tweet_ocr_res \u001b[38;5;241m=\u001b[39m get_sub_df(frame_ocr_res, parent_annotation_row)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "parent_annotation_row = all_annotations.loc[all_annotations['id'] == parent_annotations_id].iloc[0]\n",
    "frame_ocr_res = all_ocr_res.loc[all_ocr_res['frame_id'] == int(parent_annotation_row['frame_id'])]\n",
    "tweet_ocr_res = get_sub_df(frame_ocr_res, parent_annotation_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_image(entity_row):\n",
    "    if \"frame_path\" in entity_row:\n",
    "        im = Image.open(entity_row['frame_path'])\n",
    "    else:\n",
    "        im_path = db.get_frames(frame_ids=[entity_row['frame_id']]).iloc[0]['path']\n",
    "        im = Image.open(im_path)\n",
    "    e = im.crop([entity_row['x'], entity_row['y'], entity_row['x2'], entity_row['y2']])\n",
    "    e.filename = str(entity_row['id'])\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_annotations = all_tweet_annotations.loc[all_tweet_annotations['parent_annotation_id'] == parent_annotations_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = get_entity_image(parent_annotation_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_e = visualize_annotations(e, tweet_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate\n",
    "4686, 195399, 135018, 163161, 196444, 138"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hindsight_server",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
