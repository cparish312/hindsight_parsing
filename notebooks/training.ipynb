{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "sys.path.insert(0, \"../../hindsight/hindsight_server/\")\n",
    "from db import HindsightDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"twitter-2024-09-13-20-23-70120e04_with_negs\"\n",
    "project_dir = os.path.abspath(f\"../data/label_studio/{project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train.config.yaml\n",
    "config_d = {\"path\" : project_dir, \"train\" : \"images\", \"val\" : \"images\"}\n",
    "with open(os.path.join(project_dir, \"notes.json\"), 'r') as infile:\n",
    "    project_notes = json.load(infile)\n",
    "\n",
    "id_to_entity = {}\n",
    "for cat in project_notes['categories']:\n",
    "    id_to_entity[cat['id']] = cat['name']\n",
    "\n",
    "config_d[\"names\"] = id_to_entity\n",
    "\n",
    "config_f = os.path.join(project_dir, \"train_config.yaml\")\n",
    "with open(config_f, 'w') as outfile:\n",
    "    yaml.dump(config_d, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrollabel cleanup x labels to full width of image\n",
    "labels_dir = os.path.join(project_dir, \"labels\")\n",
    "for f in os.listdir(labels_dir):\n",
    "    labels_file_path = os.path.join(labels_dir, f)\n",
    "    new_label_data = list()\n",
    "    with open(labels_file_path, 'r') as infile:\n",
    "        for line in infile.readlines():\n",
    "            line_s = line.split(\" \")\n",
    "            if len(line_s) != 1:\n",
    "                if int(line_s[0]) in {0, 4, 5, 6, 10, 11, 12, 13}:\n",
    "                    new_line = \" \".join([line_s[0], str(0.5), line_s[2], str(1), line_s[4]])\n",
    "                    new_label_data.append(new_line)\n",
    "                else:\n",
    "                    new_label_data.append(line)\n",
    "\n",
    "    with open(labels_file_path, 'w') as outfile:\n",
    "        for new_line in new_label_data:\n",
    "            outfile.write(new_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add random screenshots as negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = HindsightDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = db.get_frames(impute_applications=False)\n",
    "frames = frames.loc[~frames['application'].isin([\"Twitter\", \"backCamera\", \"frontCamera\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positive_samples = len(os.listdir(labels_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = frames.sample(num_positive_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = os.path.join(project_dir, \"images\")\n",
    "for i, row in frames.iterrows():\n",
    "    filename = os.path.basename(row['path'])\n",
    "    im_dest = os.path.join(images_dir, filename)\n",
    "    shutil.copy(row['path'], im_dest)\n",
    "\n",
    "    label_dest = os.path.join(labels_dir, filename)\n",
    "    with open(label_dest, 'w') as outfile:\n",
    "        outfile.write(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.94 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.91 🚀 Python-3.10.14 torch-2.5.0.dev20240625 MPS (Apple M3 Max)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/Users/connorparish/code/hindsight_parsing/data/label_studio/twitter-2024-09-13-20-23-70120e04_with_negs/train_config.yaml, epochs=10, time=None, patience=100, batch=15, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=0, project=None, name=train162, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=True, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0, scale=0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train162\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3783802  ultralytics.nn.modules.head.Detect           [14, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25,864,426 parameters, 25,864,410 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/connorparish/code/hindsight_parsing/data/label_studio/twitter-2024-09-13-20-23-70120e04_with_negs/labels.cache... 75 images, 77 backgrounds, 0 corrupt: 100%|██████████| 150/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/connorparish/code/hindsight_parsing/data/label_studio/twitter-2024-09-13-20-23-70120e04_with_negs/labels.cache... 75 images, 77 backgrounds, 0 corrupt: 100%|██████████| 150/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train162/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000556, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.00046875), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train162\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G     0.1085     0.5258     0.4351          0        320: 100%|██████████| 10/10 [00:11<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:09<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.909      0.755      0.885      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      0.147     0.5496     0.4402          0        320: 100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:08<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.956      0.527      0.806      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G     0.1487       0.54     0.4404          0        320: 100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:11<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.888      0.549      0.871      0.711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G     0.1418     0.5266     0.4381          0        320: 100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.837      0.738      0.863      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      0.149     0.5177     0.4389          0        320: 100%|██████████| 10/10 [00:12<00:00,  1.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:08<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.838      0.701      0.787      0.698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G     0.1366     0.4766     0.4362          0        320: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:09<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.793      0.816      0.901      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.1322     0.4311     0.4375          0        320: 100%|██████████| 10/10 [00:08<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:07<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.699      0.646      0.839       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.1128     0.3766     0.4348          0        320: 100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.748      0.675      0.839      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.1009     0.3456     0.4321          0        320: 100%|██████████| 10/10 [00:08<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:15<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.835      0.691      0.906       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G    0.08924     0.3353     0.4314          0        320: 100%|██████████| 10/10 [00:08<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:04<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.861      0.671      0.923      0.825\n",
      "\n",
      "10 epochs completed in 0.091 hours.\n",
      "Optimizer stripped from runs/detect/train162/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/train162/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/train162/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.91 🚀 Python-3.10.14 torch-2.5.0.dev20240625 MPS (Apple M3 Max)\n",
      "Model summary (fused): 218 layers, 25,847,866 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:06<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        284      0.861      0.672      0.923      0.825\n",
      "discover_new_communities          3          3       0.54      0.414      0.641      0.572\n",
      "           more_posted         25         25      0.958          1      0.995      0.964\n",
      "             new_posts          3          3      0.763          1      0.995      0.995\n",
      "         partial_tweet          1          2          1          0      0.995      0.895\n",
      "pinned_by_people_you_follow          1          1          1          0      0.995      0.995\n",
      "         playing_video          5          6          1      0.962      0.995      0.953\n",
      "           plus_button         15         15          1          1      0.995       0.97\n",
      "          quoted_tweet          1          1          1          0      0.995      0.995\n",
      "      subscribe_button          1          1      0.532          1      0.995      0.995\n",
      "                 tweet         72        189      0.925      0.995      0.992      0.906\n",
      "              tweet_ad          8          8      0.859       0.76      0.871      0.839\n",
      "   twitter_bottom_menu         15         15      0.673      0.733      0.601      0.134\n",
      "      twitter_top_menu         13         15      0.938      0.867      0.929      0.506\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train162\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=config_f, epochs=10, device=\"mps\", rect=True, augment=False, close_mosaic=0, batch=15, scale=0, translate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hindsight_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
