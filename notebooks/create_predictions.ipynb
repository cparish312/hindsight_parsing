{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for creating bounding box predictions and exporting to label studio friendly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model = YOLO(\"./runs/detect/train72/weights/best.pt\")\n",
    "trained_model = YOLO(\"./runs/detect/train13/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images_dir = \"/Users/connorparish/code/hindsight_parsing/data/label_studio/twitter-2024-09-12-21-06-e4a60d42/images\"\n",
    "images = list()\n",
    "for f in os.listdir(pred_images_dir):\n",
    "    im = Image.open(os.path.join(pred_images_dir, f))\n",
    "    images.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x320 4 tweets, 189.2ms\n",
      "1: 640x320 3 tweets, 189.2ms\n",
      "2: 640x320 1 plus_button, 4 tweets, 189.2ms\n",
      "3: 640x320 3 tweets, 189.2ms\n",
      "4: 640x320 3 tweets, 189.2ms\n",
      "5: 640x320 3 tweets, 189.2ms\n",
      "6: 640x320 1 discover_new_communities, 3 tweets, 189.2ms\n",
      "7: 640x320 3 tweets, 189.2ms\n",
      "8: 640x320 3 tweets, 189.2ms\n",
      "9: 640x320 3 tweets, 189.2ms\n",
      "10: 640x320 3 tweets, 189.2ms\n",
      "11: 640x320 1 more_posted, 3 tweets, 1 tweet_ad, 189.2ms\n",
      "12: 640x320 1 plus_button, 3 tweets, 189.2ms\n",
      "13: 640x320 1 plus_button, 5 tweets, 189.2ms\n",
      "14: 640x320 3 tweets, 189.2ms\n",
      "15: 640x320 1 quoted_tweet, 4 tweets, 2 partial_tweets, 189.2ms\n",
      "16: 640x320 3 tweets, 189.2ms\n",
      "17: 640x320 1 more_posted, 3 tweets, 189.2ms\n",
      "18: 640x320 1 more_posted, 3 tweets, 189.2ms\n",
      "19: 640x320 1 more_posted, 1 plus_button, 3 tweets, 189.2ms\n",
      "20: 640x320 1 new_posts, 5 tweets, 189.2ms\n",
      "21: 640x320 1 more_posted, 4 tweets, 189.2ms\n",
      "22: 640x320 1 tweet, 1 tweet_ad, 189.2ms\n",
      "23: 640x320 1 new_posts, 2 tweets, 189.2ms\n",
      "24: 640x320 1 more_posted, 2 tweets, 1 tweet_ad, 189.2ms\n",
      "25: 640x320 1 more_posted, 3 tweets, 1 tweet_ad, 189.2ms\n",
      "26: 640x320 1 more_posted, 3 tweets, 189.2ms\n",
      "27: 640x320 2 tweets, 189.2ms\n",
      "28: 640x320 4 tweets, 189.2ms\n",
      "29: 640x320 1 more_posted, 3 tweets, 189.2ms\n",
      "Speed: 1.1ms preprocess, 189.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 320)\n"
     ]
    }
   ],
   "source": [
    "results = trained_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    image_preds_d = {}\n",
    "    image_name = os.path.basename(result.path)\n",
    "    image_preds_d['data'] = {\"image\" : f\"/data/upload/2/{image_name}\"}\n",
    "    predictions_d = {\"model_version\": \"train13\", \"score\": 0.55}\n",
    "    org_width = result.orig_shape[1]\n",
    "    org_height = result.orig_shape[0]\n",
    "    result_d_template = {\"type\": \"rectanglelabels\",        \n",
    "            \"from_name\": \"label\", \"to_name\": \"image\",\n",
    "            \"original_width\": org_width, \"original_height\": org_height,\n",
    "            \"image_rotation\": 0}\n",
    "    converted_results = list()\n",
    "    for i, box in enumerate(result.boxes):\n",
    "        result_d = result_d_template.copy()\n",
    "        result_d['id'] = f\"result{i}\"\n",
    "        value_d = {\"rotation\" : 0,\n",
    "                \"x\" : ((float(box.xyxyn[0][0])) * 100),\n",
    "                \"y\" : (float(box.xyxyn[0][1])) * 100,\n",
    "                \"width\" : ((float(box.xyxyn[0][2]) - float(box.xyxyn[0][0])) * 100), \n",
    "                \"height\": (float(box.xyxyn[0][3]) - float(box.xyxyn[0][1])) * 100, \n",
    "                \"rectanglelabels\": [result.names[int(box.cls[0])]]}\n",
    "        result_d['value'] = value_d\n",
    "        converted_results.append(result_d)\n",
    "        \n",
    "    predictions_d[\"result\"] = converted_results\n",
    "    image_preds_d['predictions'] = [predictions_d]\n",
    "    all_preds.append(image_preds_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"first_preds.json\", 'w') as outfile:\n",
    "    json.dump(all_preds, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = Image.open('/Users/connorparish/code/hindsight_parsing/data/annotations/twitter/twitter-2024-09-10-16-26-edf2ddd4/images/72312233-com-twitter-android_1725246837795.jpg')\n",
    "im = Image.open('/Users/connorparish/code/hindsight_parsing/data/annotations/twitter/twitter-2024-09-10-16-26-edf2ddd4/images/202dbdd9-com-twitter-android_1719163900778.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x320 4 tweets, 62.9ms\n",
      "Speed: 2.7ms preprocess, 62.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 320)\n"
     ]
    }
   ],
   "source": [
    "results = trained_model(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds_d = {}\n",
    "image_name = os.path.basename(result.path)\n",
    "image_preds_d['data'] = {\"image\" : f\"/data/upload/2/{image_name}\"}\n",
    "predictions_d = {\"model_version\": \"one\", \"score\": 0.55}\n",
    "# predictions_d = {\"model_version\": \"one\", \"score\": 0.56, \"cluster\": 1,\n",
    "#                  \"neighbors\" : 1, \"model\" : \"yolov9\", \"model_run\" : \"5\"}\n",
    "org_width = result.orig_shape[1]\n",
    "org_height = result.orig_shape[0]\n",
    "result_d_template = {\"type\": \"rectanglelabels\",        \n",
    "        \"from_name\": \"label\", \"to_name\": \"image\",\n",
    "        \"original_width\": org_width, \"original_height\": org_height,\n",
    "        \"image_rotation\": 0}\n",
    "converted_results = list()\n",
    "for i, box in enumerate(result.boxes):\n",
    "    result_d = result_d_template.copy()\n",
    "    result_d['id'] = f\"result{i}\"\n",
    "    # value_d = {\"rotation\" : 0,\n",
    "    #            \"x\" : float(box.xywh[0][0]),\n",
    "    #            \"y\" : float(box.xywh[0][1]),\n",
    "    #            \"width\" : float(box.xywh[0][2]), \n",
    "    #            \"height\": float(box.xywh[0][3]), \n",
    "    #            \"rectanglelabels\": [result.names[int(box.cls[0])]]}\n",
    "    value_d = {\"rotation\" : 0,\n",
    "               \"x\" : ((float(box.xyxyn[0][0])) * 100),\n",
    "               \"y\" : (float(box.xyxyn[0][1])) * 100,\n",
    "               \"width\" : ((float(box.xyxyn[0][2]) - float(box.xyxyn[0][0])) * 100), \n",
    "               \"height\": (float(box.xyxyn[0][3]) - float(box.xyxyn[0][1])) * 100, \n",
    "               \"rectanglelabels\": [\"tweet\"]}\n",
    "    result_d['value'] = value_d\n",
    "    converted_results.append(result_d)\n",
    "    \n",
    "predictions_d[\"result\"] = converted_results\n",
    "image_preds_d['predictions'] = [predictions_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 559.5109,  691.9374, 1056.9783,  827.5319],\n",
       "        [ 551.9160, 1976.3483, 1072.1681,  847.3035],\n",
       "        [ 549.3012, 1351.8394, 1077.3976,  384.0614],\n",
       "        [ 548.9635,  139.1507, 1078.0730,  278.3014]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.boxes.xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([0., 0., 0., 0.])\n",
       "conf: tensor([1.0000, 0.9999, 0.9944, 0.9898])\n",
       "data: tensor([[3.1022e+01, 2.7817e+02, 1.0880e+03, 1.1057e+03, 1.0000e+00, 0.0000e+00],\n",
       "        [1.5832e+01, 1.5527e+03, 1.0880e+03, 2.4000e+03, 9.9990e-01, 0.0000e+00],\n",
       "        [1.0602e+01, 1.1598e+03, 1.0880e+03, 1.5439e+03, 9.9444e-01, 0.0000e+00],\n",
       "        [9.9271e+00, 0.0000e+00, 1.0880e+03, 2.7830e+02, 9.8982e-01, 0.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (2400, 1088)\n",
       "shape: torch.Size([4, 6])\n",
       "xywh: tensor([[ 559.5109,  691.9374, 1056.9783,  827.5319],\n",
       "        [ 551.9160, 1976.3483, 1072.1681,  847.3035],\n",
       "        [ 549.3012, 1351.8394, 1077.3976,  384.0614],\n",
       "        [ 548.9635,  139.1507, 1078.0730,  278.3014]])\n",
       "xywhn: tensor([[0.5143, 0.2883, 0.9715, 0.3448],\n",
       "        [0.5073, 0.8235, 0.9854, 0.3530],\n",
       "        [0.5049, 0.5633, 0.9903, 0.1600],\n",
       "        [0.5046, 0.0580, 0.9909, 0.1160]])\n",
       "xyxy: tensor([[  31.0217,  278.1715, 1088.0000, 1105.7034],\n",
       "        [  15.8319, 1552.6965, 1088.0000, 2400.0000],\n",
       "        [  10.6024, 1159.8087, 1088.0000, 1543.8701],\n",
       "        [   9.9271,    0.0000, 1088.0000,  278.3014]])\n",
       "xyxyn: tensor([[0.0285, 0.1159, 1.0000, 0.4607],\n",
       "        [0.0146, 0.6470, 1.0000, 1.0000],\n",
       "        [0.0097, 0.4833, 1.0000, 0.6433],\n",
       "        [0.0091, 0.0000, 1.0000, 0.1160]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = [image_preds_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_preds.json\", 'w') as outfile:\n",
    "    json.dump(all_preds, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_preds.json\", 'r') as infile:\n",
    "    test_d = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hindsight_server",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
